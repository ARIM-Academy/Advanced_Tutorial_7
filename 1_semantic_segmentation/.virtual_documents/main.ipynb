


!git clone https://github.com/ARIM-Academy/Advanced_Tutorial_7.git
%cd Advanced_Tutorial_7


from matplotlib import pyplot as plt
import splitfolders
import shutil
import pickle
import sys

from model import *
from model2 import *
from data import *
from datasets import *


os.environ["CUDA_VISIBLE_DEVICES"] = "0"  ## KEYPOINT1

log = open("training.log", "w")
sys.stdout = log


mode = 'training'   ## KEYPOINT2





if mode == 'training' or mode == 'multiresunet_training':
    
    # shutil.rmtree('data/microplastics/train/')
    # shutil.rmtree('data/microplastics/val/')
    # shutil.rmtree('data/microplastics/test/')

    splitfolders.ratio('./data/microplastics/datasets_full_v2', output="./data/microplastics/", seed=2, ratio=(0.2, 0.2, 0.6))
    shutil.move('./data/microplastics/train/', './data/microplastics/1/')
    shutil.move('./data/microplastics/val/', './data/microplastics/2/')
    shutil.move('./data/microplastics/test/', './data/microplastics/6/')
    
    splitfolders.ratio('data/microplastics/6/', output="data/microplastics/", seed=2, ratio=(0.33, 0.33, 0.34))
    shutil.move('./data/microplastics/train/', './data/microplastics/3/')
    shutil.move('./data/microplastics/val/', './data/microplastics/4/')
    shutil.move('./data/microplastics/test/', './data/microplastics/5/')


crossval_i = 0

if os.path.isdir('data/microplastics/train/') == True:
    shutil.rmtree('data/microplastics/train/')
    shutil.rmtree('data/microplastics/test/')

os.mkdir('data/microplastics/train/')

list_dir = ['data/microplastics/1/', 'data/microplastics/2/', 'data/microplastics/3/','data/microplastics/4/','data/microplastics/5/']

copyTree(list_dir[crossval_i], 'data/microplastics/test/')

del list_dir[crossval_i]

for path in list_dir:
    copyTree(path, 'data/microplastics/train/')

print('training-testing spliting finished for {}/5 cross validation'.format(crossval_i+1))

path_list_actual = os.listdir('data/microplastics/test/image/')
testBatchSize = len(path_list_actual)

data_gen_args = dict(rotation_range=0.2,
            width_shift_range=0.05,
            height_shift_range=0.05,
            shear_range=0.05,
            zoom_range=0.05,
            horizontal_flip=True,
            fill_mode='nearest',
            validation_split=0.1)


trainGene = trainGenerator(2,'data/microplastics/train','image','label',data_gen_args,save_to_dir = None)
validGene = validGenerator(2,'data/microplastics/train','image','label',data_gen_args,save_to_dir = None)


def trainStep_1(model, Train_generator, Valid_generator, epochs, batchSize, mode, pretrained_weights = None):
    # the training phase
    total_history_dict = dict()
    for epoch in range(epochs):
        print('Epoch : {}'.format(epoch + 1))

        #model_checkpoint = ModelCheckpoint(pretrained_weights, monitor='loss', verbose=1, save_best_only=True)
        history = model.fit(Train_generator, validation_data=Valid_generator, validation_steps=30, steps_per_epoch=300,epochs=1)  # the only para changed
        
        avgiou, avgdice_coef = evaluateStep(model, batchSize=batchSize, mode=mode)
        avg_iou = [avgiou.numpy().tolist()]
        avg_dice_coef = [avgdice_coef.numpy().tolist()]
        for some_key in history.history.keys():  # save and append the results from each epoch
            current_values = []
            current_values += history.history[some_key]
            if some_key in total_history_dict:
                total_history_dict[some_key].append(current_values)
            else:
                total_history_dict[some_key] = [current_values]


        if {'test_iou', 'test_dice_coef'} <= total_history_dict.keys():
            total_history_dict['test_iou'].append(avg_iou)
            total_history_dict['test_dice_coef'].append(avg_dice_coef)
        else:
            total_history_dict['test_iou'] = [avg_iou]
            total_history_dict['test_dice_coef'] = [avg_dice_coef]
    return total_history_dict




def trainGenerator(batch_size, train_path, image_folder, mask_folder, aug_dict, 
                   image_color_mode="grayscale", mask_color_mode="grayscale", 
                   image_save_prefix="image", mask_save_prefix="mask", 
                   flag_multi_class=False, num_class=2, save_to_dir=None, 
                   target_size=(256, 256), seed=1):
    
    image_datagen = ImageDataGenerator(**aug_dict)
    mask_datagen = ImageDataGenerator(**aug_dict)

    image_generator = image_datagen.flow_from_directory(
        train_path,
        classes=[image_folder],
        class_mode=None,
        color_mode=image_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=image_save_prefix,
        seed=seed,
        subset='training'
    )

    mask_generator = mask_datagen.flow_from_directory(
        train_path,
        classes=[mask_folder],
        class_mode=None,
        color_mode=mask_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=mask_save_prefix,
        seed=seed,
        subset='training'
    )

    while True:  # Ensure continuous data generation
        image_batch, mask_batch = next(zip(image_generator, mask_generator)) 
        img, mask = adjustData(image_batch, mask_batch, flag_multi_class, num_class)
        yield (img, mask)


model = unet()


# Assuming you know the number of samples in trainGene (e.g., from data preprocessing)
num_train_samples =len(path_list_actual)

model_checkpoint = ModelCheckpoint('unet_microplastics.keras', monitor='loss', verbose=1, save_best_only=True)
history = model.fit(trainGene, steps_per_epoch=num_train_samples, epochs=10, callbacks=[model_checkpoint])


# model_checkpoint = ModelCheckpoint('unet_microplastics.hdf5', monitor='loss', verbose=1, save_best_only=True)
# history = model.fit_generator(trainGene,steps_per_epoch=3,epochs=10,callbacks=[model_checkpoint])
## KEYPOINT4,5

total_history_dict = trainStep_1(model, trainGene, validGene, 
                            epochs=5, batchSize=testBatchSize, 
                            mode=mode, 
                            pretrained_weights='unet_microplastics_{}.keras'.format(crossval_i))


total_history_dict


plt.plot(total_history_dict['accuracy'], 'b-')
plt.plot(total_history_dict['iou'], 'g-')
plt.plot(total_history_dict['dice_coef'], 'r-')
plt.plot(total_history_dict['test_iou'], 'g--')
plt.plot(total_history_dict['test_dice_coef'], 'r--')
plt.title('Model Accuracy')
plt.ylabel('Metrics')
plt.xlabel('Epoch')
plt.legend(['accuracy', 'iou', 'dice_coef','test_iou', 'test_dice_coef'], loc='upper left')
# plt.show()
plt.grid()
plt.savefig('training_unet_{}.png'.format(crossval_i))
plt.close()
a_file = open("data_unet_{}.pkl".format(crossval_i), "wb")
pickle.dump(total_history_dict, a_file)
a_file.close()
# a_file = open("data{}.pkl".format(crossval_i), "rb")
# output = pickle.load(a_file)
# print(output)






for crossval_i in range(5):    ## KEYPOINT3
    if os.path.isdir('data/microplastics/train/') == True:
        shutil.rmtree('data/microplastics/train/')
        shutil.rmtree('data/microplastics/test/')
    os.mkdir('data/microplastics/train/')

    list_dir = ['data/microplastics/1/', 'data/microplastics/2/', 'data/microplastics/3/','data/microplastics/4/','data/microplastics/5/']

    copyTree(list_dir[crossval_i], 'data/microplastics/test/')
    del list_dir[crossval_i]
    
    for path in list_dir:
        copyTree(path, 'data/microplastics/train/')

    print('training-testing spliting finished for {}/5 cross validation'.format(crossval_i+1))
    print(mode)
    
    path_list_actual = os.listdir('data/microplastics/test/image/')
    testBatchSize = len(path_list_actual)


    data_gen_args = dict(rotation_range=0.2,
                        width_shift_range=0.05,
                        height_shift_range=0.05,
                        shear_range=0.05,
                        zoom_range=0.05,
                        horizontal_flip=True,
                        fill_mode='nearest',
                        validation_split=0.1)
    
    trainGene = trainGenerator(2,'data/microplastics/train','image','label',data_gen_args,save_to_dir = None)
    validGene = validGenerator(2,'data/microplastics/train','image','label',data_gen_args,save_to_dir = None)

    print ('OK')


    if mode == 'training':
        model = unet()
        # model_checkpoint = ModelCheckpoint('unet_microplastics.hdf5', monitor='loss', verbose=1, save_best_only=True)
        # history = model.fit_generator(trainGene,steps_per_epoch=3,epochs=10,callbacks=[model_checkpoint])
        ## KEYPOINT4,5

        total_history_dict = trainStep(model, trainGene, validGene, 
                                       epochs=100, batchSize=testBatchSize, 
                                       mode=mode, 
                                       pretrained_weights='unet_microplastics_{}.keras'.format(crossval_i))
        
        plt.plot(total_history_dict['accuracy'], 'b-')
        plt.plot(total_history_dict['iou'], 'g-')
        plt.plot(total_history_dict['dice_coef'], 'r-')
        plt.plot(total_history_dict['test_iou'], 'g--')
        plt.plot(total_history_dict['test_dice_coef'], 'r--')
        plt.title('Model Accuracy')
        plt.ylabel('Metrics')
        plt.xlabel('Epoch')
        plt.legend(['accuracy', 'iou', 'dice_coef','test_iou', 'test_dice_coef'], loc='upper left')
        # plt.show()
        plt.grid()
        plt.savefig('training_unet_{}.png'.format(crossval_i))
        plt.close()
        a_file = open("data_unet_{}.pkl".format(crossval_i), "wb")
        pickle.dump(total_history_dict, a_file)
        a_file.close()
        # a_file = open("data{}.pkl".format(crossval_i), "rb")
        # output = pickle.load(a_file)
        # print(output)

    elif mode == 'testing':
        model = unet('unet_microplastics.hdf5')
        
    elif mode == 'multiresunet_training':
        model = MultiResUnet()
        # model_checkpoint = ModelCheckpoint('unet_microplastics.hdf5', monitor='loss', verbose=1, save_best_only=True)
        # history = model.fit_generator(trainGene,steps_per_epoch=3,epochs=10,callbacks=[model_checkpoint])
        total_history_dict = trainStep(model, trainGene, validGene, epochs=100, batchSize=testBatchSize, mode=mode, pretrained_weights='multiresunet_microplastics_{}.hdf5'.format(crossval_i))
        plt.plot(total_history_dict['accuracy'], 'b-')
        plt.plot(total_history_dict['iou'], 'g-')
        plt.plot(total_history_dict['dice_coef'], 'r-')
        plt.plot(total_history_dict['test_iou'], 'g--')
        plt.plot(total_history_dict['test_dice_coef'], 'r--')
        plt.title('Model Accuracy')
        plt.ylabel('Metrics')
        plt.xlabel('Epoch')
        plt.legend(['accuracy', 'iou', 'dice_coef','test_iou', 'test_dice_coef'], loc='upper left')
        # plt.show()
        plt.grid()
        plt.savefig('training_multiresunet_{}.png'.format(crossval_i))
        plt.close()
        a_file = open("data_multiresunet_{}.pkl".format(crossval_i), "wb")
        pickle.dump(total_history_dict, a_file)
        a_file.close()

    elif mode == 'multiresunet_testing':
        model = MultiResUnet('multiresunet_microplastics.hdf5')





# results = model.predict(testGene,batch_size=30, verbose=1)
# results = testResize("data/microplastics/test/image", results, 30, flag_resize=True)
# results = (results>0.5)
#
# if mode == 'training' or mode == 'testing':
#     saveResult("data/microplastics/test/image", "data/microplastics/result", results)
#     evaluateResult("data/microplastics/result", "data/microplastics/test/label", 30)
#     print('*************')
# elif mode == 'multiresunet_training' or mode  == 'multiresunet_testing':
#     saveResult("data/microplastics/test/image", "data/microplastics/result2", results)
#     evaluateResult("data/microplastics/result2", "data/microplastics/test/label", 30)
#     print('-------------')
